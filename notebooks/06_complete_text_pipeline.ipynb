{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8742fea-b467-4328-bcd2-0d5da1e635ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "from data.notes_loader import NotesLoader\n",
    "from data.text_preprocessing import TextPreprocessor, TextConfig\n",
    "from data.text_integration import TextTabularIntegrator, create_stratified_splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae84347-2c9f-4ee4-b59d-1036d1266003",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 1: CARREGAR DADOS TABULARES\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697db7a2-5b7d-4f4b-a994-dbb77d52aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PASSO 1: Carregando dados tabulares...\n",
      "‚úì ED stays carregados: 189,158\n",
      "  - Pacientes: 99,346\n",
      "  - Critical Outcome: 10,105 (5.3%)\n",
      "  - Lengthened ED Stay: 11,227 (5.9%)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä PASSO 1: Carregando dados tabulares...\")\n",
    "edstays = pd.read_parquet('../data/processed/labeled_data.parquet')\n",
    "\n",
    "print(f\"‚úì ED stays carregados: {len(edstays):,}\")\n",
    "print(f\"  - Pacientes: {edstays['subject_id'].nunique():,}\")\n",
    "print(f\"  - Critical Outcome: {edstays['critical_outcome'].sum():,} ({edstays['critical_outcome'].mean()*100:.1f}%)\")\n",
    "print(f\"  - Lengthened ED Stay: {edstays['lengthened_ed_stay'].sum():,} ({edstays['lengthened_ed_stay'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace60e30-c4f4-46ca-803a-2e450f6b3d06",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 2: CARREGAR E FILTRAR NOTAS\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5578bca-16a7-4a66-b2cf-5a066ab9fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.notes_loader:‚úì Categorias dispon√≠veis: discharge, radiology\n",
      "INFO:data.notes_loader:üìñ Carregando discharge notes em chunks de 10,000...\n",
      "INFO:data.notes_loader:   Carregando colunas: ['subject_id', 'hadm_id', 'charttime', 'storetime', 'text', 'note_id', 'note_type', 'note_seq']\n",
      "INFO:data.notes_loader:   Parseando datas: ['charttime', 'storetime']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ PASSO 2: Carregando notas cl√≠nicas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.notes_loader:   Processados 10 chunks, 21,744 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 20 chunks, 43,674 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 30 chunks, 65,552 notas mantidas\n",
      "INFO:data.notes_loader:‚úì discharge: 72,544 notas carregadas\n",
      "INFO:data.notes_loader:üìñ Carregando radiology notes em chunks de 10,000...\n",
      "INFO:data.notes_loader:   Carregando colunas: ['subject_id', 'hadm_id', 'charttime', 'storetime', 'text', 'note_id', 'note_type', 'note_seq']\n",
      "INFO:data.notes_loader:   Parseando datas: ['charttime', 'storetime']\n",
      "INFO:data.notes_loader:   Processados 10 chunks, 10,302 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 20 chunks, 20,758 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 30 chunks, 31,974 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 40 chunks, 41,738 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 50 chunks, 52,557 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 60 chunks, 63,327 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 70 chunks, 73,478 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 80 chunks, 84,306 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 90 chunks, 94,888 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 100 chunks, 105,105 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 110 chunks, 115,892 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 120 chunks, 125,837 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 130 chunks, 136,320 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 140 chunks, 146,807 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 150 chunks, 156,706 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 160 chunks, 167,524 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 170 chunks, 177,874 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 180 chunks, 188,689 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 190 chunks, 199,366 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 200 chunks, 209,811 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 210 chunks, 220,265 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 220 chunks, 230,342 notas mantidas\n",
      "INFO:data.notes_loader:   Processados 230 chunks, 240,441 notas mantidas\n",
      "INFO:data.notes_loader:‚úì radiology: 242,658 notas carregadas\n",
      "INFO:data.notes_loader:üìã Colunas no dataset final: ['note_id', 'subject_id', 'hadm_id', 'note_type', 'note_seq', 'charttime', 'storetime', 'text', 'note_category', 'category_priority']\n",
      "INFO:data.notes_loader:‚úì Timestamps dispon√≠veis: ['charttime', 'storetime']\n",
      "INFO:data.notes_loader:  - charttime: 315,202 (100.0%) n√£o-nulos\n",
      "INFO:data.notes_loader:  - storetime: 315,202 (100.0%) n√£o-nulos\n",
      "INFO:data.notes_loader:‚úÖ Total: 315,202 notas\n",
      "INFO:data.notes_loader:‚è±Ô∏è Aplicando filtro temporal nas notas...\n",
      "INFO:data.notes_loader:  - Notas com hadm_id v√°lido: 242,658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Notas carregadas: 315,202\n",
      "\n",
      "üéØ Aplicando estrat√©gia h√≠brida...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.notes_loader:  - Notas ap√≥s merge com ED stays: 240,693\n",
      "INFO:data.notes_loader:  - Notas com timestamps v√°lidos: 240,693\n",
      "INFO:data.notes_loader:‚úì Filtro temporal: 242,658 ‚Üí 95,275 notas (39.3% mantidas)\n",
      "INFO:data.notes_loader:‚è±Ô∏è Aplicando filtro temporal nas notas...\n",
      "INFO:data.notes_loader:  - Notas com hadm_id v√°lido: 72,544\n",
      "INFO:data.notes_loader:  - Notas ap√≥s merge com ED stays: 71,862\n",
      "INFO:data.notes_loader:  - Notas com timestamps v√°lidos: 71,862\n",
      "INFO:data.notes_loader:‚úì Filtro temporal: 72,544 ‚Üí 9,690 notas (13.4% mantidas)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Notas ap√≥s filtro h√≠brido: 104,965\n",
      "  - Radiology (0h):  95,275\n",
      "  - Discharge (12h): 9,690\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìñ PASSO 2: Carregando notas cl√≠nicas...\")\n",
    "loader = NotesLoader(data_root='../data/raw/')\n",
    "\n",
    "# Carregar notas brutas\n",
    "notes = loader.load_notes(\n",
    "    categories=['discharge', 'radiology'],\n",
    "    subject_ids=edstays['subject_id'].unique().tolist(),\n",
    "    hadm_ids=edstays['hadm_id'].unique().tolist(),\n",
    "    chunksize=10000\n",
    ")\n",
    "\n",
    "print(f\"‚úì Notas carregadas: {len(notes):,}\")\n",
    "\n",
    "# Aplicar estrat√©gia h√≠brida\n",
    "print(\"\\nüéØ Aplicando estrat√©gia h√≠brida...\")\n",
    "\n",
    "rad_notes = notes[notes['note_category'] == 'radiology'].copy()\n",
    "dis_notes = notes[notes['note_category'] == 'discharge'].copy()\n",
    "\n",
    "rad_filtered = loader.filter_temporal(rad_notes, edstays, time_buffer_hours=0)\n",
    "dis_filtered = loader.filter_temporal(dis_notes, edstays, time_buffer_hours=12)\n",
    "\n",
    "notes_temporal = pd.concat([rad_filtered, dis_filtered], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úì Notas ap√≥s filtro h√≠brido: {len(notes_temporal):,}\")\n",
    "print(f\"  - Radiology (0h):  {len(rad_filtered):,}\")\n",
    "print(f\"  - Discharge (12h): {len(dis_filtered):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157b037-9e41-4d0b-a50c-706f58912909",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 3: PR√â-PROCESSAMENTO DE TEXTO\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa5e17b-36a3-4e67-a944-1d44a8a3201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_preprocessing:üßπ Pr√©-processando 104,965 notas...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ PASSO 3: Limpando texto...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_preprocessing:‚úì Notas v√°lidas: 104,952/104,965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Notas v√°lidas ap√≥s limpeza: 104,952\n",
      "  - Taxa de valida√ß√£o: 100.0%\n",
      "\n",
      "üìä Estat√≠sticas de texto limpo:\n",
      "  - Tamanho m√©dio: 1904 chars\n",
      "  - Mediana: 911 chars\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüßπ PASSO 3: Limpando texto...\")\n",
    "\n",
    "config = TextConfig(\n",
    "    max_tokens_per_segment=512,\n",
    "    min_text_length=50,\n",
    "    lowercase=False  # Manter case para nomes de drogas\n",
    ")\n",
    "\n",
    "preprocessor = TextPreprocessor(config)\n",
    "notes_clean = preprocessor.preprocess_dataframe(notes_temporal, text_column='text')\n",
    "\n",
    "# Filtrar apenas notas v√°lidas\n",
    "notes_valid = notes_clean[notes_clean['is_valid']].copy()\n",
    "\n",
    "print(f\"‚úì Notas v√°lidas ap√≥s limpeza: {len(notes_valid):,}\")\n",
    "print(f\"  - Taxa de valida√ß√£o: {len(notes_valid)/len(notes_temporal)*100:.1f}%\")\n",
    "\n",
    "# Estat√≠sticas de texto\n",
    "print(f\"\\nüìä Estat√≠sticas de texto limpo:\")\n",
    "print(f\"  - Tamanho m√©dio: {notes_valid['cleaned_length'].mean():.0f} chars\")\n",
    "print(f\"  - Mediana: {notes_valid['cleaned_length'].median():.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba8cfd-92b5-422b-ae6e-326768e76691",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 4: INTEGRA√á√ÉO TEXTO-TABULAR\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e4339d-61df-4da3-be06-d0e92db28e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_integration:üîó Associando notas aos stays (strategy=priority)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó PASSO 4: Integrando texto com dados tabulares...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_integration:‚úì 61,924 stays com texto\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Integra√ß√£o completa:\n",
      "  - Total ED stays: 189,158\n",
      "  - Com texto: 61,924\n",
      "  - Cobertura: 32.7%\n",
      "  - Tamanho m√©dio: 2182 chars\n",
      "\n",
      "  Distribui√ß√£o por tipo de nota:\n",
      "    - RR: 54,207\n",
      "    - DS: 7,653\n",
      "    - AR: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîó PASSO 4: Integrando texto com dados tabulares...\")\n",
    "\n",
    "integrator = TextTabularIntegrator()\n",
    "\n",
    "# Associar notas aos ED stays (priorizar discharge > radiology)\n",
    "df_integrated = integrator.associate_notes_to_stays(\n",
    "    df_tabular=edstays,\n",
    "    notes=notes_valid,\n",
    "    strategy='priority'  # discharge tem prioridade sobre radiology\n",
    ")\n",
    "\n",
    "# Estat√≠sticas de integra√ß√£o\n",
    "stats = integrator.get_statistics(df_integrated)\n",
    "print(f\"\\n‚úì Integra√ß√£o completa:\")\n",
    "print(f\"  - Total ED stays: {stats['total_stays']:,}\")\n",
    "print(f\"  - Com texto: {stats['with_text']:,}\")\n",
    "print(f\"  - Cobertura: {stats['text_coverage']*100:.1f}%\")\n",
    "print(f\"  - Tamanho m√©dio: {stats['avg_text_length']:.0f} chars\")\n",
    "\n",
    "# Distribui√ß√£o por categoria\n",
    "if 'by_category' in stats:\n",
    "    print(f\"\\n  Distribui√ß√£o por tipo de nota:\")\n",
    "    for cat, count in stats['by_category'].items():\n",
    "        print(f\"    - {cat}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc398051-bea7-476e-8885-b26d84d6077f",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 5: CRIAR DATASET MULTI-MODAL\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc7ce6a-7b59-43bc-a496-29adee66224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_integration:üé® Criando dataset multi-modal...\n",
      "INFO:data.text_integration:‚úì Dataset criado: (189158, 57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé® PASSO 5: Criando dataset multi-modal...\n",
      "‚úì Dataset criado: (189158, 57)\n",
      "  - Features tabulares: 51\n",
      "  - Com texto: 61,924 (32.7%)\n",
      "  - Positivos: 10,105 (5.3%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüé® PASSO 5: Criando dataset multi-modal...\")\n",
    "\n",
    "dataset = integrator.create_multimodal_dataset(\n",
    "    df_integrated,\n",
    "    text_column='cleaned_text',\n",
    "    outcome_column='critical_outcome'  # Podemos criar datasets para ambos os outcomes\n",
    ")\n",
    "\n",
    "print(f\"‚úì Dataset criado: {dataset.shape}\")\n",
    "print(f\"  - Features tabulares: {len([c for c in dataset.columns if c.startswith('triage_') or c.startswith('lab_')])}\")\n",
    "print(f\"  - Com texto: {dataset['has_text'].sum():,} ({dataset['has_text'].mean()*100:.1f}%)\")\n",
    "print(f\"  - Positivos: {dataset['outcome'].sum():,} ({dataset['outcome'].mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2536b-8963-42f3-9d26-acdc8e07219e",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 6: SPLITS ESTRATIFICADOS\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8319465a-ab2d-4c31-b835-830d843f8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è PASSO 6: Criando splits estratificados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.text_integration:‚úì Splits criados: train=151326, val=18916, test=18916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì TRAIN: 151,326 amostras\n",
      "     - Com texto: 49,599 (32.8%)\n",
      "     - Positivos: 8,084 ( 5.3%)\n",
      "\n",
      "‚úì VAL  : 18,916 amostras\n",
      "     - Com texto: 6,146 (32.5%)\n",
      "     - Positivos: 1,011 ( 5.3%)\n",
      "\n",
      "‚úì TEST : 18,916 amostras\n",
      "     - Com texto: 6,179 (32.7%)\n",
      "     - Positivos: 1,010 ( 5.3%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚úÇÔ∏è PASSO 6: Criando splits estratificados...\")\n",
    "\n",
    "splits = create_stratified_splits(\n",
    "    dataset,\n",
    "    outcome_col='outcome',\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Salvar splits\n",
    "for split_name, split_df in splits.items():\n",
    "    output_path = f'../data/processed/multimodal_{split_name}.parquet'\n",
    "    split_df.to_parquet(output_path, index=False)\n",
    "    \n",
    "    # Estat√≠sticas do split\n",
    "    n_with_text = split_df['has_text'].sum()\n",
    "    n_positive = split_df['outcome'].sum()\n",
    "    \n",
    "    print(f\"\\n‚úì {split_name.upper():5s}: {len(split_df):5,} amostras\")\n",
    "    print(f\"     - Com texto: {n_with_text:5,} ({n_with_text/len(split_df)*100:4.1f}%)\")\n",
    "    print(f\"     - Positivos: {n_positive:5,} ({n_positive/len(split_df)*100:4.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20792e-d127-4137-8b31-74f7987e5948",
   "metadata": {},
   "source": [
    "## ============================================================\n",
    "## PASSO 7: VALIDA√á√ÉO FINAL\n",
    "## ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670f75fc-bc00-4d70-9172-c873248e6a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "‚úÖ PIPELINE DE DADOS TEXTUAIS CONCLU√çDO\n",
      "============================================================\n",
      "\n",
      "üìÅ Arquivos gerados:\n",
      "  ‚úì multimodal_train.parquet\n",
      "  ‚úì multimodal_val.parquet\n",
      "  ‚úì multimodal_test.parquet\n",
      "\n",
      "üéØ Pr√≥ximos passos:\n",
      "  1. Implementar lineariza√ß√£o de features (Fase 3)\n",
      "  2. Fine-tune BioGPT (SFT)\n",
      "  3. Treinamento com RL (PPO)\n",
      "  4. Compara√ß√£o: Tabular vs. Multi-modal\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PIPELINE DE DADOS TEXTUAIS CONCLU√çDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÅ Arquivos gerados:\")\n",
    "print(\"  ‚úì multimodal_train.parquet\")\n",
    "print(\"  ‚úì multimodal_val.parquet\")\n",
    "print(\"  ‚úì multimodal_test.parquet\")\n",
    "\n",
    "print(\"\\nüéØ Pr√≥ximos passos:\")\n",
    "print(\"  1. Implementar lineariza√ß√£o de features (Fase 3)\")\n",
    "print(\"  2. Fine-tune BioGPT (SFT)\")\n",
    "print(\"  3. Treinamento com RL (PPO)\")\n",
    "print(\"  4. Compara√ß√£o: Tabular vs. Multi-modal\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184f8464-474b-4282-94b3-d05b684b5f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VALIDA√á√ÉO DOS SPLITS\n",
      "\n",
      "============================================================\n",
      "\n",
      "TRAIN:\n",
      "  - Shape: (151326, 57)\n",
      "  - Colunas: ['subject_id', 'hadm_id', 'stay_id', 'cleaned_text', 'outcome', 'triage_completeness', 'triage_age', 'triage_gender_male', 'triage_gender_female', 'triage_heart_rate']... (57 total)\n",
      "\n",
      "  ‚úì Integridade:\n",
      "    - Nulls em 'outcome': 0\n",
      "    - Nulls em 'has_text': 0\n",
      "    - Texto vazio (quando has_text=True): 0\n",
      "\n",
      "  üìä Distribui√ß√£o:\n",
      "    - Com texto: 32.8%\n",
      "    - Outcome positivo: 5.3%\n",
      "\n",
      "  üéØ Estratifica√ß√£o (texto x outcome):\n",
      "outcome      0     1\n",
      "has_text            \n",
      "False     69.5  26.9\n",
      "True      30.5  73.1\n",
      "\n",
      "VAL:\n",
      "  - Shape: (18916, 57)\n",
      "  - Colunas: ['subject_id', 'hadm_id', 'stay_id', 'cleaned_text', 'outcome', 'triage_completeness', 'triage_age', 'triage_gender_male', 'triage_gender_female', 'triage_heart_rate']... (57 total)\n",
      "\n",
      "  ‚úì Integridade:\n",
      "    - Nulls em 'outcome': 0\n",
      "    - Nulls em 'has_text': 0\n",
      "    - Texto vazio (quando has_text=True): 0\n",
      "\n",
      "  üìä Distribui√ß√£o:\n",
      "    - Com texto: 32.5%\n",
      "    - Outcome positivo: 5.3%\n",
      "\n",
      "  üéØ Estratifica√ß√£o (texto x outcome):\n",
      "outcome      0     1\n",
      "has_text            \n",
      "False     69.8  26.5\n",
      "True      30.2  73.5\n",
      "\n",
      "TEST:\n",
      "  - Shape: (18916, 57)\n",
      "  - Colunas: ['subject_id', 'hadm_id', 'stay_id', 'cleaned_text', 'outcome', 'triage_completeness', 'triage_age', 'triage_gender_male', 'triage_gender_female', 'triage_heart_rate']... (57 total)\n",
      "\n",
      "  ‚úì Integridade:\n",
      "    - Nulls em 'outcome': 0\n",
      "    - Nulls em 'has_text': 0\n",
      "    - Texto vazio (quando has_text=True): 0\n",
      "\n",
      "  üìä Distribui√ß√£o:\n",
      "    - Com texto: 32.7%\n",
      "    - Outcome positivo: 5.3%\n",
      "\n",
      "  üéØ Estratifica√ß√£o (texto x outcome):\n",
      "outcome      0     1\n",
      "has_text            \n",
      "False     69.8  24.4\n",
      "True      30.2  75.6\n",
      "\n",
      "============================================================\n",
      "‚úÖ VALIDA√á√ÉO CONCLU√çDA\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VALIDA√á√ÉO DOS SPLITS\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üîç VALIDA√á√ÉO DOS SPLITS\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    df = pd.read_parquet(f'../data/processed/multimodal_{split_name}.parquet')\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    print(f\"  - Shape: {df.shape}\")\n",
    "    print(f\"  - Colunas: {list(df.columns)[:10]}... ({len(df.columns)} total)\")\n",
    "    \n",
    "    # Verificar integridade\n",
    "    print(f\"\\n  ‚úì Integridade:\")\n",
    "    print(f\"    - Nulls em 'outcome': {df['outcome'].isnull().sum()}\")\n",
    "    print(f\"    - Nulls em 'has_text': {df['has_text'].isnull().sum()}\")\n",
    "    print(f\"    - Texto vazio (quando has_text=True): {(df['has_text'] & df['cleaned_text'].isnull()).sum()}\")\n",
    "    \n",
    "    # Distribui√ß√£o\n",
    "    print(f\"\\n  üìä Distribui√ß√£o:\")\n",
    "    print(f\"    - Com texto: {df['has_text'].mean()*100:.1f}%\")\n",
    "    print(f\"    - Outcome positivo: {df['outcome'].mean()*100:.1f}%\")\n",
    "    \n",
    "    # Estratifica√ß√£o\n",
    "    print(f\"\\n  üéØ Estratifica√ß√£o (texto x outcome):\")\n",
    "    crosstab = pd.crosstab(df['has_text'], df['outcome'], normalize='columns') * 100\n",
    "    print(crosstab.round(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VALIDA√á√ÉO CONCLU√çDA\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e91b5-167f-4bb7-956c-891b244b5b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
