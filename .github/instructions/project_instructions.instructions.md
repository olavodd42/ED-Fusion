---
applyTo: '**'
---
Plano Estruturado para Re-implementa√ß√£o do ED-Copilot com Dados Textuais
üìã Vis√£o Geral do Projeto
Objetivo: Re-implementar e estender o ED-Copilot incorporando dados textuais (notas cl√≠nicas) al√©m dos dados tabulares, utilizando MIMIC-IV-ED + MIMIC-IV Notes.
Diferencial: O artigo original usa apenas dados tabulares linearizados. Sua implementa√ß√£o integrar√° notas cl√≠nicas para potencialmente melhorar as predi√ß√µes.

üéØ Fase 1: Prepara√ß√£o e Fundamenta√ß√£o (2-3 semanas)
1.1 Configura√ß√£o do Ambiente

 Obter acesso ao MIMIC-IV via PhysioNet (completar curso CITI)
 Configurar ambiente Python (3.8+)
 Instalar depend√™ncias principais:

  - transformers, pytorch
  - stable-baselines3 (RL)
  - pandas, numpy, scikit-learn
  - BioGPT, ClinicalBERT (modelos biom√©dicos)

 Configurar GPU (A6000, V100 ou similar)
 Criar reposit√≥rio Git estruturado

1.2 Estudo Aprofundado

 Revisar conceitos de RL (PPO, MDP)
 Estudar arquitetura de Language Models para sa√∫de
 Analisar c√≥digo original do ED-Copilot no GitHub
 Documentar fluxo completo do pipeline original

Entreg√°vel: Ambiente configurado + documento de fundamenta√ß√£o te√≥rica

üìä Fase 2: Curadoria dos Dados (3-4 semanas)
2.1 Dados Tabulares (Replica√ß√£o do MIMIC-ED-Assist)
2.1.1 Extra√ß√£o Base

 Baixar MIMIC-IV-ED (v2.2) e MIMIC-IV
 Aplicar filtros do artigo:

Pacientes admitidos (hospitalizados)
Idade ‚â• 18 anos
Com informa√ß√µes de triagem completas
Remover testes duplicados no mesmo paciente



2.1.2 Sele√ß√£o de Features
Triage (9 vari√°veis):

 Demografia: idade, sexo
 Sinais vitais: FC, PA sist√≥lica/diast√≥lica, FR, temperatura, SpO2
 Cl√≠nica: chief complaint, ESI acuity, dor auto-relatada
 Hist√≥rico: comorbidades, visitas pr√©vias ICU/ED

Laborat√≥rio (68 testes em 12 grupos):

 Implementar agrupamento conforme Tabela 7 do artigo:

CBC, CHEM, COAG, UA, LACTATE, LFTs, LIPASE, LYTES, BLOOD GAS, CARDIO, TOX, INFLAM


 Extrair timestamps para calcular time-cost m√©dio por grupo
 Calcular ED LOS (length of stay)

2.1.3 Labels

 Critical Outcome: morte hospitalar OU transfer√™ncia ICU em 12h
 Lengthened ED Stay: ED LOS > 24 horas

2.2 Dados Textuais (Extens√£o Proposta) ‚≠ê
2.2.1 Extra√ß√£o de Notas Cl√≠nicas

 Acessar tabela noteevents do MIMIC-IV
 Filtrar notas relevantes por categoria:

Discharge Summary (resumo da alta)
Radiology (laudos de imagem)
ED Physician Notes (notas do m√©dico emergencista)
Nursing (evolu√ß√£o de enfermagem)



2.2.2 Pr√©-processamento de Texto

 Remover informa√ß√µes identific√°veis (PHI)
 Limpar formata√ß√£o (remover XML, caracteres especiais)
 Segmentar notas longas (m√°x 512 tokens por segmento)
 Associar notas ao encounter correto via hadm_id e stay_id
 Filtrar notas temporalmente:

Usar apenas notas dispon√≠veis ANTES do desfecho
Simular disponibilidade temporal no ED



2.2.3 Estrat√©gias de Incorpora√ß√£o
Definir como integrar texto ao modelo:

 Op√ß√£o A: Concatenar embedding de texto ao final da sequ√™ncia tabulada
 Op√ß√£o B: Multi-modal fusion (aten√ß√£o cruzada entre tabular e texto)
 Op√ß√£o C: Usar texto apenas para enriquecer chief complaint

2.3 Pipeline de Dados

 Criar splits train/val/test (80/10/10) estratificados
 Garantir mesma distribui√ß√£o de classes
 Salvar dados processados em formato eficiente (Parquet/HDF5)
 Gerar estat√≠sticas descritivas (Tabela 1 estendida)

Entreg√°vel: Dataset MIMIC-ED-Assist-Plus com dados tabulares + textuais

üß† Fase 3: Implementa√ß√£o do Modelo Base (4-5 semanas)
3.1 Lineariza√ß√£o de Features Tabulares
3.1.1 Template para Triage
python# Exemplo de lineariza√ß√£o
"Patient age: 65 | gender: Male | heart_rate: 98 | ... | 
chief_complaint: Chest pain | [EOS]"
3.1.2 Template para Laborat√≥rio
python# Grupo CBC
"CBC: Hemoglobin: 12.5 g/dL | WBC: 8.2 K/uL | ... | [EOS]"
```

- [ ] Implementar fun√ß√£o de lineariza√ß√£o modular
- [ ] Testar com nomes reais vs. feature IDs (ablation)
- [ ] Validar comprimento de sequ√™ncia (m√°x 656 tokens no artigo)

### 3.2 Arquitetura do Modelo

#### 3.2.1 Backbone de Linguagem
- [ ] Carregar BioGPT-345M pr√©-treinado
- [ ] Alternativas: ClinicalBERT, BioBERT, Llama-7B (LORA)
- [ ] Implementar forward pass:
```
  [x0, r0, [EOS]0, x1, r1, [EOS]1, ..., xn, rn, [EOS]n, y]
```

#### 3.2.2 Cabe√ßas de Predi√ß√£o (MLPs)
- [ ] **MLP œÜ**: predi√ß√£o do pr√≥ximo grupo de lab (12 classes)
  - Input: hidden state h_{i-1}
  - Output: probabilidades sobre 12 grupos
  
- [ ] **MLP œà**: predi√ß√£o de desfecho (2 tarefas)
  - Input: hidden state h_n (√∫ltimo [EOS])
  - Output: probabilidade de critical outcome / lengthened stay

- [ ] Arquitetura: 3 camadas, hidden_size=1024, dropout

### 3.3 Supervised Fine-Tuning (SFT)

#### 3.3.1 Loss Functions
- [ ] Loss autoregressivo para labs:
```
  L_lab = -1/n Œ£ log p_œÜ(x_i | h_{<i})
```
  
- [ ] Loss para desfecho:
```
  L_y = -log p_œà(y | h_{‚â§n})
```
  
- [ ] Loss combinado: `L = L_lab + L_y`

#### 3.3.2 Treinamento
- [ ] Configurar hiperpar√¢metros (Tabela 8):
  - Learning rate: 1e-5
  - Batch size: 32
  - Epochs: 15
  - Optimizer: AdamW
  - Class weight: 10 (para desbalanceamento)
  
- [ ] Implementar early stopping (valida√ß√£o)
- [ ] Salvar checkpoints

**Entreg√°vel**: Modelo SFT treinado + curvas de aprendizado

---

## üéÆ Fase 4: Reinforcement Learning (3-4 semanas)

### 4.1 Formula√ß√£o do MDP

#### 4.1.1 Espa√ßo de Estados
- [ ] Estado s_i: hist√≥rico observado `[x0, r0, ..., xi, ri]`
- [ ] Representa√ß√£o: hidden states do LM

#### 4.1.2 Espa√ßo de A√ß√µes
- [ ] A√ß√µes: {12 grupos de lab} ‚à™ {y+, y-} (predi√ß√£o final)
- [ ] M√°scara de a√ß√µes: apenas grupos **n√£o observados** ou grupos que o paciente recebeu (offline constraint)

#### 4.1.3 Recompensas
- [ ] Definir fun√ß√£o de recompensa:
```
  R = TN + Œ±*TP - Œ≤*Cost

Œ± controla trade-off sensitivity/specificity
Œ≤ controla trade-off F1/time-cost
 Time-cost: soma dos custos dos grupos selecionados
 Cost por grupo: m√©dia observada nos dados (Tabela 7)

4.2 Treinamento com PPO
4.2.1 Configura√ß√£o

 Usar Stable-Baselines3 com masked actor-critic
 Freezar pesos do LM (apenas treinar policy MLP)
 Hiperpar√¢metros (Tabela 8):

Buffer steps: 2048
Epochs: 10
Batch size: 128
Œ± = 15, Œ≤ = 1/100



4.2.2 Experience Replay

 Coletar trajet√≥rias de pacientes
 Calcular advantages com GAE
 Otimizar loss clipped surrogate

4.2.3 Monitoramento

 Logging de m√©tricas:

Reward m√©dio por epis√≥dio
N√∫mero m√©dio de labs selecionados
Time-cost m√©dio
F1-score na valida√ß√£o



Entreg√°vel: ED-Copilot completo com RL

üìù Fase 5: Extens√£o com Dados Textuais (3-4 semanas)
5.1 ED-Copilot-Text: Arquitetura Multi-Modal
5.1.1 Encoder de Texto

 Usar ClinicalBERT ou Bio_ClinicalBERT
 Processar notas cl√≠nicas relevantes:

python  text_embedding = ClinicalBERT(notes)  # [batch, 768]
```

#### 5.1.2 Estrat√©gias de Fus√£o

**Op√ß√£o 1: Late Fusion (mais simples)**
- [ ] Concatenar embedding de texto ao final:
```
  [tabular_sequence, [SEP], text_embedding, [EOS]]
Op√ß√£o 2: Cross-Attention (mais avan√ßado)

 Implementar camada de aten√ß√£o entre modalidades:

python  attended_features = CrossAttention(
      query=tabular_features,
      key=text_features,
      value=text_features
  )
Op√ß√£o 3: Hierarchical

 Encoder de texto ‚Üí resumo
 Injetar resumo como token especial na sequ√™ncia tabular

5.1.3 Implementa√ß√£o

 Modificar forward pass para aceitar ambas modalidades
 Ajustar MLPs de predi√ß√£o
 Re-treinar com SFT + RL

5.2 Variantes a Testar

 V1: Apenas chief complaint textual (baseline)
 V2: Chief complaint + discharge summary
 V3: Chief complaint + nursing notes (temporalmente apropriado)
 V4: Todas as notas dispon√≠veis no ED

Entreg√°vel: ED-Copilot-Text implementado

üß™ Fase 6: Experimentos e Avalia√ß√£o (3-4 semanas)
6.1 M√©tricas de Avalia√ß√£o
6.1.1 Acur√°cia Preditiva

 F1-score
 AUC-ROC
 Sensitivity (recall)
 Specificity

6.1.2 Efici√™ncia

 Average time-cost (minutos)
 N√∫mero m√©dio de labs sugeridos
 ED LOS estimado

6.2 Experimentos Principais
6.2.1 Baseline Comparisons (Replicar Tabela 2)

 Random Forest
 XGBoost
 LightGBM
 DNN 3-layer
 SM-DDPO
 ED-Copilot (sua implementa√ß√£o)
 ED-Copilot-Text (novo)

6.2.2 Ablation Studies (Replicar Tabela 3)

 Impacto da lineariza√ß√£o
 Feature importance (w/o triage, w/o CBC, w/o CHEM)
 Compara√ß√£o de backbones (BioGPT vs. ClinicalBERT vs. Llama)
 Impacto dos dados textuais (novo):

Apenas tabular
Tabular + chief complaint
Tabular + notas completas



6.2.3 An√°lise de Personaliza√ß√£o (Replicar Tabela 4)

 Performance em cohorts:

Top 2 lab groups
Middle 6 lab groups
Rare labs


 Verificar se texto ajuda mais em casos complexos

6.2.4 Subgroup Analysis (Replicar Tabela 6)

 Por sexo
 Por faixa et√°ria (18-30, 31-60, 61-90)
 Fairness metrics

6.2.5 Time-Cost Curves (Replicar Figura 2)

 F1 vs. time constraint
 AUC vs. time constraint
 Comparar tabular vs. multi-modal

6.2.6 Simula√ß√£o sem Restri√ß√£o Offline (Se√ß√£o 6.5)

 ED-Copilot (restricted)
 ED-Copilot (unrestricted) com imputa√ß√£o

6.3 An√°lises Adicionais

 Interpretabilidade:

Aten√ß√£o em palavras-chave das notas
Labs mais frequentemente selecionados


 Casos de uso cl√≠nicos:

Exemplos qualitativos de recomenda√ß√µes
Compara√ß√£o com protocolo padr√£o



Entreg√°vel: Resultados completos + figuras + tabelas

üìÑ Fase 7: Documenta√ß√£o do TCC (3-4 semanas)
7.1 Estrutura do Documento
Cap√≠tulo 1: Introdu√ß√£o

 Contextualiza√ß√£o: ED crowding como problema de sa√∫de p√∫blica
 Objetivos: re-implementar + estender com texto
 Contribui√ß√µes esperadas

Cap√≠tulo 2: Fundamenta√ß√£o Te√≥rica

 Emergency Department: fluxo de atendimento
 Machine Learning para diagn√≥stico cl√≠nico
 Language Models em sa√∫de (BioGPT, ClinicalBERT)
 Reinforcement Learning (PPO, MDP)
 Processamento de texto cl√≠nico

Cap√≠tulo 3: Trabalhos Relacionados

 Benchmarks em MIMIC (MIMIC-Extract, etc.)
 ED-Copilot original (an√°lise cr√≠tica)
 Modelos multi-modais em EHR
 Cost-effective ML em medicina

Cap√≠tulo 4: Materiais e M√©todos

 Dataset: MIMIC-IV-ED + Notes
 Pr√©-processamento (tabular + texto)
 Arquitetura do modelo
 Processo de treinamento (SFT + RL)
 M√©tricas de avalia√ß√£o

Cap√≠tulo 5: Resultados

 Estat√≠sticas descritivas
 Compara√ß√£o com baselines
 Ablation studies
 An√°lise de personaliza√ß√£o
 Impacto dos dados textuais

Cap√≠tulo 6: Discuss√£o

 Interpreta√ß√£o dos resultados
 Vantagens da abordagem multi-modal
 Limita√ß√µes (offline benchmark, single center data)
 Implica√ß√µes cl√≠nicas

Cap√≠tulo 7: Conclus√£o

 S√≠ntese dos achados
 Trabalhos futuros (clinical trial, outras modalidades)

7.2 Materiais Complementares

 C√≥digo-fonte bem documentado (GitHub)
 Notebooks de an√°lise explorat√≥ria
 Ambiente reprodut√≠vel (Docker/requirements.txt)
 Apresenta√ß√£o de defesa

Entreg√°vel: TCC completo

‚è±Ô∏è Cronograma Sugerido (20-24 semanas)
FaseDura√ß√£oSemanas1. Prepara√ß√£o2-3 sem1-32. Curadoria de Dados3-4 sem4-73. Modelo Base4-5 sem8-124. Reinforcement Learning3-4 sem13-165. Extens√£o Textual3-4 sem17-206. Experimentos3-4 sem21-247. Documenta√ß√£oParalelo-

üéØ Checkpoints de Valida√ß√£o
Checkpoint 1 (Semana 7)

Dataset criado e validado
Estat√≠sticas descritivas alinhadas com artigo original

Checkpoint 2 (Semana 12)

Modelo SFT treinando e convergindo
F1-score pr√≥ximo aos baselines

Checkpoint 3 (Semana 16)

RL funcionando
Time-cost reduzindo significativamente

Checkpoint 4 (Semana 20)

Vers√£o multi-modal implementada
Compara√ß√£o tabular vs. texto completa

Checkpoint Final (Semana 24)

Todos os experimentos finalizados
Draft do TCC pronto


üöÄ Diferenciais da Sua Implementa√ß√£o

Dados Textuais: Incorpora√ß√£o de notas cl√≠nicas (principal inova√ß√£o)
An√°lise Multi-Modal: Compara√ß√£o sistem√°tica tabular vs. texto
Interpretabilidade: An√°lise de aten√ß√£o em texto m√©dico
Reprodutibilidade: C√≥digo aberto e bem documentado
Extensibilidade: Arquitetura modular para futuras modalidades (imagem, etc.)


‚ö†Ô∏è Riscos e Mitiga√ß√µes
RiscoProbabilidadeImpactoMitiga√ß√£oAcesso aos dados demoraM√©diaAltoIniciar processo de credenciamento imediatamenteRecursos computacionais insuficientesBaixaM√©dioUsar Google Colab Pro ou AWS credits acad√™micosModelo n√£o convergeM√©diaAltoCome√ßar com hiperpar√¢metros do paper, ajustar gradualmenteDados textuais n√£o melhoram performanceM√©diaM√©dioAinda √© uma contribui√ß√£o v√°lida (an√°lise negativa)Tempo insuficienteM√©diaAltoPriorizar modelo base, deixar extens√µes como "trabalhos futuros"

üìö Recursos √öteis
C√≥digo

Reposit√≥rio original: https://github.com/cxcscmu/ED-Copilot
Stable-Baselines3: https://stable-baselines3.readthedocs.io/
Hugging Face Transformers: https://huggingface.co/docs/transformers

Papers

BioGPT: https://arxiv.org/abs/2210.10341
ClinicalBERT: https://arxiv.org/abs/1904.05342
PPO: https://arxiv.org/abs/1707.06347

Datasets

MIMIC-IV: https://physionet.org/content/mimiciv/
MIMIC-IV-ED: https://physionet.org/content/mimic-iv-ed/
MIMIC-IV-Note: https://physionet.org/content/mimic-iv-note/


Pr√≥ximos Passos Imediatos:

Iniciar processo de credenciamento MIMIC
Configurar ambiente de desenvolvimento
Estudar c√≥digo original do ED-Copilot
Definir escopo exato da extens√£o textual com orientador